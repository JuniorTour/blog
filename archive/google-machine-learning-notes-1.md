## è°·æ­Œæœºå™¨å­¦ä¹ é€Ÿæˆè¯¾ç¨‹ç¬”è®° -ï¼ˆä¸€ï¼‰- 2018/10/08

https://developers.google.com/machine-learning/crash-course/prereqs-and-prework



## ä¸€ã€ç®€ä»‹

### 0. å‰ææ¡ä»¶å’Œå‡†å¤‡å·¥ä½œ

- Python åŸºç¡€
- å…¥é—¨ä»£æ•°çŸ¥è¯†



TODOï¼š

- Bashã€Shell
- æ•°å­¦ï¼š[å¯¹æ•°](https://wikipedia.org/wiki/Logarithm)å’Œå¯¹æ•°æ–¹ç¨‹å¼ï¼Œä¾‹å¦‚ y=ln(1+e^z)ã€å¼ é‡ï¼ˆhttps://www.tensorflow.org/programmers_guide/tensorsï¼‰.....ï¼ˆè®¡åˆ’éšç”¨éšå­¦ï¼‰



## äºŒã€æœºå™¨å­¦ä¹ æ¦‚å¿µ

### 1. æœºå™¨å­¦ä¹ ç®€ä»‹ 

æœºå™¨å­¦ä¹ çš„æ„ä¹‰

1. æé«˜ç¼–ç¨‹æ•ˆç‡ï¼Œç¼©çŸ­ç¼–ç¨‹æ—¶é—´ã€‚
2. è‡ªå®šä¹‰äº§å“ï¼Œå¢å¼ºäº§å“çš„é€‚åº”æ€§ã€‚
3. è§£å†³ä¸€äº›åªæœ‰äººæ‰èƒ½å¿«é€Ÿè§£å†³çš„é—®é¢˜ï¼Œä¾‹å¦‚è®¤è¯†ä¸€å¼ é¢å­”ã€‚
4. æ”¹å˜æ€è€ƒé—®é¢˜çš„æ–¹å¼ï¼Œä»ä»¥é€»è¾‘å’Œæ•°å­¦æ€ç»´æ€è€ƒé—®é¢˜åˆ°ä»è‡ªç„¶ç§‘å­¦çš„è§’åº¦è§‚å¯Ÿ`ä¸ç¡®å®šçš„ä¸–ç•Œ`ã€‚



### 2. æ¡†æ¶å¤„ç†

#### 1. ç›‘ç£å¼æœºå™¨å­¦ä¹ ï¼šæœºå™¨å­¦ä¹ ç³»ç»Ÿé€šè¿‡å­¦ä¹ å¦‚ä½•ç»„åˆè¾“å…¥ä¿¡æ¯æ¥å¯¹ä»æœªè§è¿‡çš„æ•°æ®åšå‡ºæœ‰ç”¨çš„é¢„æµ‹

`æ ‡ç­¾ï¼ˆlabelï¼‰`ï¼šæŒ‡æˆ‘ä»¬è¦é¢„æµ‹çš„çœŸå®äº‹ç‰©ï¼š**y**ï¼Œä¾‹å¦‚åƒåœ¾é‚®ä»¶è¿‡æ»¤ä¸­çš„â€œåƒåœ¾é‚®ä»¶æˆ–éåƒåœ¾é‚®ä»¶â€ã€‚

`ç‰¹å¾ï¼ˆfeatureï¼‰`ï¼šæŒ‡ç”¨äºæè¿°æ•°æ®çš„è¾“å…¥å˜é‡ï¼š**xä¸‹æ ‡i**ï¼Œä¾‹å¦‚é‚®ä»¶çš„å†…å®¹ã€æ ‡é¢˜ã€æ”¶å‘ä»¶äººã€‚â€ã€‚

`æ ·æœ¬ï¼ˆexampleï¼‰`ï¼šæŒ‡æ•°æ®çš„ç‰¹å®šå®ä¾‹ï¼š**x**ï¼Œä¸€ä»½æ•°æ®ï¼Œä¾‹å¦‚ä¸€å°é‚®ä»¶ã€‚

æ ·æœ¬å¯ä»¥`æœ‰æ ‡ç­¾ - {ç‰¹å¾, æ ‡ç­¾}ï¼š(x, y)ï¼Œç”¨äºè®­ç»ƒæ¨¡å‹`ã€‚

æˆ–`æ— æ ‡ç­¾ - {ç‰¹å¾, æ ‡ç­¾}ï¼š(x, y)ï¼Œç”¨äºå¯¹æ–°æ•°æ®åšå‡ºé¢„æµ‹`ã€‚

åœ¨æˆ‘ä»¬çš„åƒåœ¾é‚®ä»¶æ£€æµ‹å™¨ç¤ºä¾‹ä¸­ï¼Œæœ‰æ ‡ç­¾æ ·æœ¬æ˜¯ç”¨æˆ·æ˜ç¡®æ ‡è®°ä¸ºâ€œåƒåœ¾é‚®ä»¶â€æˆ–â€œéåƒåœ¾é‚®ä»¶â€çš„å„ä¸ªç”µå­é‚®ä»¶ã€‚

æœ€ç»ˆï¼Œé€šè¿‡è¿™äº›æ•°æ®å¾—åˆ°ä¸€ä¸ª`æ¨¡å‹ modle`ï¼Œå®šä¹‰äº†ç‰¹å¾ä¸æ ‡ç­¾ä¹‹é—´çš„å…³ç³»ã€‚

#### 2. å›å½’ä¸åˆ†ç±»

- **å›å½’**æ¨¡å‹å¯é¢„æµ‹è¿ç»­å€¼ã€‚ä¾‹å¦‚ï¼šåŠ åˆ©ç¦å°¼äºšå·ä¸€æ ‹æˆ¿äº§çš„ä»·å€¼æ˜¯å¤šå°‘ï¼Ÿç”¨æˆ·ç‚¹å‡»æ­¤å¹¿å‘Šçš„æ¦‚ç‡æ˜¯å¤šå°‘ï¼Ÿ
- **åˆ†ç±»**æ¨¡å‹å¯é¢„æµ‹ç¦»æ•£å€¼ã€‚ä¾‹å¦‚ï¼šæŸä¸ªæŒ‡å®šç”µå­é‚®ä»¶æ˜¯åƒåœ¾é‚®ä»¶è¿˜æ˜¯éåƒåœ¾é‚®ä»¶ï¼Ÿè¿™æ˜¯ä¸€å¼ ç‹—ã€çŒ«è¿˜æ˜¯ä»“é¼ å›¾ç‰‡ï¼Ÿ



#### 3. ç»ƒä¹ é¢˜

- ä¸»é¢˜æ ‡å¤´ä¸­çš„å­—è¯é€‚åˆåš`æ ‡ç­¾`ã€‚âŒ		ä¸»é¢˜æ ‡å¤´ä¸­çš„å­—è¯å¯èƒ½æ˜¯ä¼˜è´¨`ç‰¹å¾`ï¼Œä½†ä¸é€‚åˆåšæ ‡ç­¾ã€‚

- ç”¨æˆ·å–œæ¬¢çš„é‹å­æ˜¯ä¸€ç§å®ç”¨æ ‡ç­¾ã€‚âŒ           å–œå¥½ä¸æ˜¯å¯è§‚å¯Ÿä¸”å¯é‡åŒ–çš„æŒ‡æ ‡ã€‚æˆ‘ä»¬èƒ½åšåˆ°æœ€å¥½çš„å°±æ˜¯é’ˆå¯¹ç”¨æˆ·çš„å–œå¥½æ¥æœç´¢å¯è§‚å¯Ÿçš„ä»£ç†æŒ‡æ ‡ã€‚



### 3. æ·±å…¥äº†è§£æœºå™¨å­¦ä¹ (Descending into ML)ï¼šä»æ•°æ®ä¸­å­¦ä¹ æ¨¡å‹

#### 1. è§†é¢‘è®²åº§

![ml-1](/Users/jianannan/Desktop/ml-notes/ml-1.png)

ä»¥è¯¾ç¨‹ä¸­çš„`æ•°æ®é›†`ï¼ˆä¸Šå›¾ï¼‰ä¸ºä¾‹ï¼Œxè½´ä¸ºæˆ¿å±‹é¢ç§¯ï¼Œyè½´ä¸º**æˆ‘ä»¬å°è¯•é¢„æµ‹çš„**æˆ¿å±‹ä»·æ ¼ï¼Œä¸€ä¸ªä¸ªçš„ç‚¹å°±æ˜¯`ç”¨æ ‡ç­¾æ ‡è®°çš„æ ·æœ¬`ï¼Œå›¾ä¸­çš„ç›´çº¿å°±æ˜¯æˆ‘ä»¬å¼•å¯¼ä¸€ä¸ªå…·æœ‰åˆä¸­æ™ºåŠ›æ°´å¹³çš„æœºå™¨å¾—å‡ºçš„`æ¨¡å‹`ï¼Œå¯ä»¥å°†å…¶å®šä¹‰ä¸º`y=wx + b`ã€‚

æˆ‘ä»¬å¦‚ä½•çŸ¥é“è¿™ä¸ªæ¨¡å‹æ˜¯å¦æ˜¯æ­£ç¡®çš„å‘¢ï¼Ÿç”¨è¯¯å·®æ¥åˆ¤æ–­ã€‚

`è¯¯å·®`å¯ä»¥ä»æœ¬è´¨ä¸Šåæ˜ è¿™æ¡çº¿åœ¨é¢„æµ‹ä»»ä½•ç»™å®šæ ·æœ¬æ—¶çš„æ•ˆæœå¦‚ä½•ã€‚ä»¥å›¾ä¸­çš„è¿™äº›ç‚¹ä¸ºä¾‹ï¼Œæœ‰äº›å…·æœ‰æ­£è¯¯å·®ã€æœ‰äº›å…·æœ‰è´Ÿè¯¯å·®ã€æœ‰äº›è¯¯å·®å‡ ä¹å°±æ˜¯é›¶ã€‚

ç”¨æ›´æ­£å¼çš„æ–¹å¼å®šä¹‰å³ï¼šç»™å®šæ ·æœ¬çš„ **L2 æŸå¤±**ï¼ˆ**å¹³æ–¹æŸå¤±**ï¼‰ä¹Ÿç§°ä¸º`å¹³æ–¹è¯¯å·®` =` é¢„æµ‹å€¼å’Œæ ‡ç­¾å€¼ä¹‹å·®çš„å¹³æ–¹ = (è§‚å¯Ÿå€¼ - é¢„æµ‹å€¼)^2 = (y - y')^2`ã€‚

å¹¶ä¸”ï¼Œ**æˆ‘ä»¬åœ¨è®­ç»ƒæ¨¡å‹æ—¶ï¼Œå¹¶éä¸“æ³¨äºå°½é‡å‡å°‘æŸä¸€ä¸ªæ ·æœ¬çš„è¯¯å·®ï¼Œè€Œæ˜¯ç€çœ¼äºæœ€å¤§é™åº¦çš„å‡å°‘æ•´ä¸ªæ•°æ®é›†çš„è¯¯å·®ã€‚**



#### 2. çº¿æ€§å›å½’

ä»¥æ ¹æ®ä¸€ä¸ªæ•°æ®é›†æ¥é¢„æµ‹èŸ‹èŸ€é¸£å«å£°ä¸æ¸©åº¦çš„å…³ç³»ä¸ºä¾‹ï¼š

1. å¯ä»¥ç”¨ä»£æ•°çŸ¥è¯†å†™å‡ºè¿™ä¸ªå…³ç³»ï¼šy = mx + bï¼Œ

- y æŒ‡çš„æ˜¯æ¸©åº¦ï¼ˆä»¥æ‘„æ°åº¦è¡¨ç¤ºï¼‰ï¼Œå³æˆ‘ä»¬è¯•å›¾é¢„æµ‹çš„å€¼ã€‚
- m æŒ‡çš„æ˜¯ç›´çº¿çš„æ–œç‡ã€‚
- x æŒ‡çš„æ˜¯æ¯åˆ†é’Ÿçš„é¸£å«å£°æ¬¡æ•°ï¼Œå³è¾“å…¥ç‰¹å¾çš„å€¼ã€‚
- b æŒ‡çš„æ˜¯ y è½´æˆªè·ã€‚



2. ä½†æ˜¯æŒ‰ç…§æœºå™¨å­¦ä¹ çš„æƒ¯ä¾‹ï¼Œæ¨¡å‹çš„æ–¹ç¨‹å¼åº”è¯¥æ˜¯è¿™æ ·çš„ï¼šy ' = b + w1 x1ï¼Œ

- y 'æŒ‡çš„æ˜¯é¢„æµ‹[æ ‡ç­¾](https://developers.google.com/machine-learning/crash-course/framing/ml-terminology#labels)ï¼ˆç†æƒ³è¾“å‡ºå€¼ï¼‰ã€‚
- w1 æŒ‡çš„æ˜¯ç‰¹å¾ 1 çš„`æƒé‡ï¼ˆweightï¼‰`ã€‚æƒé‡ä¸ä¸Šæ–‡ä¸­ç”¨ m è¡¨ç¤ºçš„â€œæ–œç‡â€çš„æ¦‚å¿µç›¸åŒã€‚
- b æŒ‡çš„æ˜¯`åå·®ï¼ˆbiasï¼‰`ï¼ˆy è½´æˆªè·ï¼‰ã€‚è€Œåœ¨ä¸€äº›æœºå™¨å­¦ä¹ æ–‡æ¡£ä¸­ï¼Œå®ƒç§°ä¸º w0ã€‚
- x1 æŒ‡çš„æ˜¯[ç‰¹å¾](https://developers.google.com/machine-learning/crash-course/framing/ml-terminology#features)ï¼ˆå·²çŸ¥è¾“å…¥é¡¹ï¼‰ã€‚

æ ‡ï¼ˆä¾‹å¦‚ w1 å’Œ x1ï¼‰é¢„ç¤ºç€å¯ä»¥ç”¨å¤šä¸ªç‰¹å¾æ¥è¡¨ç¤ºæ›´å¤æ‚çš„æ¨¡å‹ã€‚ä¾‹å¦‚ï¼Œå…·æœ‰ä¸‰ä¸ªç‰¹å¾çš„æ¨¡å‹å¯ä»¥é‡‡ç”¨ä»¥ä¸‹æ–¹ç¨‹å¼ï¼š

> yâ€²= b + w1x1 + w2x2 + w3x3



#### 3. è®­ç»ƒä¸æŸå¤±

`è®­ç»ƒæ¨¡å‹`è¡¨ç¤ºé€šè¿‡æœ‰æ ‡ç­¾æ ·æœ¬æ¥å­¦ä¹ ï¼ˆç¡®å®šï¼‰æ‰€æœ‰æƒé‡ï¼ˆw1ï¼Œæ–œç‡ï¼‰å’Œåå·®ï¼ˆbï¼Œæˆªè·ï¼‰çš„ç†æƒ³å€¼ã€‚

åœ¨ç›‘ç£å¼å­¦ä¹ ä¸­ï¼Œæœºå™¨å­¦ä¹ ç®—æ³•é€šè¿‡ä»¥ä¸‹æ–¹å¼æ„å»ºæ¨¡å‹ï¼šæ£€æŸ¥å¤šä¸ªæ ·æœ¬å¹¶å°è¯•æ‰¾å‡ºå¯æœ€å¤§é™åº¦åœ°å‡å°‘æŸå¤±çš„æ¨¡å‹ï¼›è¿™ä¸€è¿‡ç¨‹ç§°ä¸º**ç»éªŒé£é™©æœ€å°åŒ–**ã€‚

**æŸå¤±**æ˜¯ä¸€ä¸ªæ•°å€¼ï¼Œè¡¨ç¤ºå¯¹äºå•ä¸ªæ ·æœ¬è€Œè¨€æ¨¡å‹é¢„æµ‹çš„å‡†ç¡®ç¨‹åº¦ã€‚

è®­ç»ƒæ¨¡å‹çš„ç›®æ ‡æ˜¯ä»æ‰€æœ‰æ ·æœ¬ä¸­æ‰¾åˆ°ä¸€ç»„å¹³å‡æŸå¤±â€œè¾ƒå°â€çš„æƒé‡å’Œåå·®ã€‚ä¾‹å¦‚ä¸‹å›¾ï¼Œå³ä¾§çš„æ¨¡å‹ç›¸å¯¹äºå·¦ä¾§`æŸå¤±`å°±æ›´å°ã€‚

![LossSideBySide](/Users/jianannan/Desktop/ml-notes/LossSideBySide.png)

æˆ‘ä»¬ç”¨`å¹³æ–¹æŸå¤±ï¼ˆL2æŸå¤±ï¼‰`æ¥æ›´ç§‘å­¦åœ°æ±‡æ€»ä¸€ä¸ªæ¨¡å‹çš„æŸå¤±ã€‚

1. å•ä¸ªæ ·æœ¬çš„`å¹³æ–¹æŸå¤±`å…¬å¼å¦‚ä¸‹ï¼š

```
  = the square of the difference between the label and the prediction
  = (observation - prediction(x))2
  = (y - y')2
```

2. æ¯ä¸ªæ ·æœ¬çš„å¹³å‡å¹³æ–¹æŸå¤±ç§°ä¹‹ä¸ºï¼š**å‡æ–¹è¯¯å·®** (**MSE - Mean Squared Error**)ï¼Œå…¬å¼å¦‚ä¸‹ï¼š

![mse-formula](/Users/jianannan/Desktop/ml-notes/mse-formula.png)

- (x, y) æŒ‡çš„æ˜¯æ ·æœ¬ã€‚
- Prediction(x) æŒ‡çš„æ˜¯æƒé‡ï¼ˆw1ï¼Œæ–œç‡ï¼‰å’Œåå·®ï¼ˆï¼‰ä¸ç‰¹å¾é›† x ç»“åˆçš„å‡½æ•°ã€‚
- D æŒ‡çš„æ˜¯åŒ…å«å¤šä¸ªæœ‰æ ‡ç­¾æ ·æœ¬ï¼ˆå³ (x,y)ï¼‰çš„æ•°æ®é›†ã€‚
- N æŒ‡çš„æ˜¯ D ä¸­çš„æ ·æœ¬æ•°é‡ã€‚



è¿™æ˜¯å‡ºè‰²çš„æ¨¡å‹å—ï¼Ÿæ‚¨å¦‚ä½•åˆ¤æ–­è¯¯å·®æœ‰å¤šå¤§ï¼Ÿ

> ç”±äºå‡æ–¹è¯¯å·® (MSE) å¾ˆéš¾è§£è¯»ï¼Œå› æ­¤æˆ‘ä»¬ç»å¸¸æŸ¥çœ‹çš„æ˜¯å‡æ–¹æ ¹è¯¯å·® (RMSE - Root Mean Squared Error ï¼Œå³ MSE å¼€æ–¹)ã€‚
>
> â€”â€”[ä½¿ç”¨ TensorFlow çš„èµ·å§‹æ­¥éª¤](https://colab.research.google.com/notebooks/mlcc/first_steps_with_tensor_flow.ipynb?utm_source=mlcc&utm_campaign=colab-external&utm_medium=referral&utm_content=firststeps-colab&hl=zh-cn)



#### 3. ç»ƒä¹ é¢˜

![mse-excercise](/Users/jianannan/Desktop/ml-notes/mse-excercise.png)

è‚‰çœ¼ç›´è§‚åˆ¤æ–­å‡ºçš„å‡æ–¹è¯¯å·®å¹¶ä¸ä¸€å®šå‡†ç¡®ã€‚





### é™ä½æŸå¤±

#### 1. è§†é¢‘è®²åº§ï¼ˆä¸€ï¼‰



#### 2. ä»¥`è¿­ä»£æ–¹å¼`é™ä½æœºå™¨å­¦ä¹ æ¨¡å‹çš„æŸå¤±ã€‚



![GradientDescentDiagram](/Users/jianannan/Desktop/ml-notes/GradientDescentDiagram.svg)



ç®€è€Œè¨€ä¹‹ï¼Œå°±æ˜¯ç”¨`çŒœæµ‹ã€è¯•é”™`çš„æ–¹å¼ï¼Œå°½å¯èƒ½åœ°å¾—å‡ºæŸå¤±æœ€ä½ã€æœ€ä½³çš„æ¨¡å‹ã€‚

å¯¹äºçº¿æ€§å›å½’(y' = b + w1x1)é—®é¢˜ï¼Œäº‹å®è¯æ˜åˆå§‹å€¼å¹¶ä¸é‡è¦ã€‚æˆ‘ä»¬å¯ä»¥éšæœºé€‰æ‹©å€¼ä½œä¸ºw1ï¼ˆæƒé‡ï¼Œæ–œç‡ï¼‰ å’Œ bï¼ˆ`åå·®ï¼ˆbiasï¼‰`ï¼Œæˆªè·ï¼‰ï¼Œç„¶åä½¿ç”¨æŸå¤±å‡½æ•°ï¼ˆä¾‹å¦‚å¹³æ–¹æŸå¤±å‡½æ•°ï¼‰å°†å¾—å‡ºçš„ `é¢„æµ‹å€¼ - y'` å’Œ `ç‰¹å¾ x å¯¹åº”çš„æ­£ç¡®æ ‡ç­¾ - y`è¾“å…¥ï¼Œå¾—å‡ºæŸå¤±å‡½æ•°çš„å€¼ã€‚

æˆ‘ä»¬å¯ä»¥é€šè¿‡ä¸æ–­åœ°è¿­ä»£ï¼ˆåœ¨ä¸Šå›¾ä¸­ç»¿è‰²éƒ¨åˆ†ï¼ŒæŒ‰ç…§ä¸€å®šçš„ç­–ç•¥æ›´æ–°è®¡ç®—çš„å‚æ•°ï¼‰ï¼Œç›´åˆ°æ€»ä½“æŸå¤±ä¸å†å˜åŒ–æˆ–è‡³å°‘å˜åŒ–æå…¶ç¼“æ…¢ä¸ºæ­¢ã€‚è¿™æ—¶å€™ï¼Œæˆ‘ä»¬å¯ä»¥è¯´è¯¥æ¨¡å‹å·²**æ”¶æ•›**(convergence)ã€‚



#### 3. é™ä½æŸå¤± (Reducing Loss)ï¼šæ¢¯åº¦ä¸‹é™æ³•ï¼ˆgradient descentï¼‰

è¿­ä»£æ–¹æ³•ä¸­çš„`æ›´æ–°è®¡ç®—å‚æ•°`è¿™ä¸€æ­¥ï¼Œåè€Œä¸å®ï¼Œä¸å¤Ÿå…·ä½“ï¼Œæ•ˆç‡å¤ªä½ã€‚

**æ¢¯åº¦**æ˜¯åå¯¼æ•°çš„**çŸ¢é‡**ï¼›å®ƒå¯ä»¥è®©æ‚¨äº†è§£å“ªä¸ªæ–¹å‘è·ç¦»ç›®æ ‡â€œæ›´è¿‘â€æˆ–â€œæ›´è¿œâ€ã€‚

>  ` æ¢¯åº¦ã€åå¯¼æ•°`éƒ½æ˜¯å¾®ç§¯åˆ†ä¸­çš„æ¦‚å¿µï¼Œé€šå¸¸æœºå™¨å­¦ä¹ æ¡†æ¶ä¼šå¸®åŠ©å¤„ç†è¿™éƒ¨åˆ†è®¡ç®—ï¼Œä½¿ç”¨è€…ç”šè‡³ä¸å¿…äº†è§£å…¶å…·ä½“å«ä¹‰ï¼ˆå…¶å®æˆ‘çœ‹äº†ä¸€éï¼Œæ²¡çœ‹æ‡‚ã€‚ã€‚ã€‚ï¼‰

![GradientDescentGradientStep](/Users/jianannan/Desktop/ml-notes/GradientDescentGradientStep.svg)



æ¢¯åº¦ä¸‹é™æ³•å³é€šè¿‡è®¡ç®—æŸå¤±æ›²çº¿åœ¨æŸå¤„çš„**è´Ÿ**æ¢¯åº¦ï¼Œä»è€Œå¾—çŸ¥å¦‚ä½•æ”¹å˜ æƒé‡ ï¼Œä½¿å¾— æŸå¤± å°½å¿«é™ä½çš„ç®—æ³•ã€‚

åœ¨æŸå¤±æ›²çº¿ä¸Šçš„æ¯ä¸€ç‚¹è®¡ç®—å‡ºæ¥çš„è´Ÿæ¢¯åº¦å¤§å°çš„ä¸€éƒ¨åˆ†ï¼ˆä¹‹æ‰€ä»¥åªæ˜¯ä¸€éƒ¨åˆ†çš„åŸå› ï¼Œè§ä¸‹ä¸€èŠ‚ï¼‰ä¼šä¸èµ·ç‚¹ç›¸åŠ ï¼Œå¾—å‡ºä¸‹ä¸€ä¸ªç‚¹çš„ä½ç½®ï¼Œä¸€æ¬¡è¿™æ ·çš„æ“ä½œï¼Œç§°ä¹‹ä¸º`æ­¥`ã€‚

ä¹‹åï¼Œæ¢¯åº¦é™ä½ç®—æ³•ä¼šä¸æ–­é‡å¤ä¸Šä¸€æ­¥ï¼Œç›´åˆ°é€æ¸æ¥è¿‘æœ€ä½ç‚¹ã€‚



#### 4. å­¦ä¹ é€Ÿç‡

æ¢¯åº¦æ˜¯ä¸€ä¸ªå…·æœ‰æ–¹å‘å’Œå¤§å°çš„çŸ¢é‡ï¼Œæ¢¯åº¦ä¸‹é™ç®—æ³•ä¼šç”¨æ¢¯åº¦ä»¥åŠä¸€ä¸ªç§°ä¹‹ä¸º`å­¦ä¹ é€Ÿç‡`çš„`æ ‡é‡`ï¼Œä»è€Œç¡®å®šæŸå¤±æ›²çº¿ä¸Šçš„ä¸‹ä¸€ä¸ªç‚¹ã€‚

ä¾‹å¦‚ï¼Œæ¢¯åº¦å¤§å°ä¸º 2.5 ï¼Œå­¦ä¹ é€Ÿç‡ä¸º 0.01ï¼Œåˆ™æ¢¯åº¦ä¸‹é™æ³•ç®—æ³•ä¼šé€‰æ‹©è·ç¦»å‰ä¸€ä¸ªç‚¹ 0.025 çš„ä½ç½®ä½œä¸ºä¸‹ä¸€ä¸ªç‚¹ã€‚



å­¦ä¹ é€Ÿç‡æ˜¯ä¸€ä¸ªå¾ˆé‡è¦çš„`è¶…å‚æ•°ï¼ˆhypeparameterï¼‰`ï¼Œæ˜¯è°ƒèŠ‚æ•´ä¸ªç®—æ³•çš„é‡è¦å·¥å…·ã€‚

è¿‡å¤§çš„å­¦ä¹ é€Ÿç‡å¯èƒ½ä¼šå¯¼è‡´æ°¸è¿œæ— æ³•å¾—åˆ°æœ€åˆé€‚çš„æƒé‡ï¼Œä¸‹ä¸€ä¸ªç‚¹ä¼šåœ¨Uå‹æ›²çº¿çš„åº•éƒ¨æ¥å›è·³è·ƒï¼Œå´å§‹ç»ˆæ— æ³•åˆ°è¾¾æœ€åº•éƒ¨ã€‚

è€Œè¿‡å°çš„å­¦ä¹ é€Ÿç‡åˆ™å¯èƒ½æ‹–æ…¢ç®—æ³•çš„å­¦ä¹ æ•ˆç‡ï¼Œå¯¼è‡´è¿›è¡Œäº†è¿‡å¤šæ¬¡çš„è®¡ç®—æ‰åˆ°è¾¾æŸå¤±æ›²çº¿çš„åº•éƒ¨ã€‚



é€šå¸¸æ¥è¯´ï¼Œä¼šæœ‰ä¸€ä¸ª `æœ€åˆé€‚çš„å­¦ä¹ é€Ÿç‡`ï¼Œå‘ç°è¿™ä¸ªå­¦ä¹ é€Ÿç‡å°±æ˜¯ç¼–ç¨‹äººå‘˜çš„ä¸»è¦å·¥ä½œã€‚

![LearningRateJustRight](/Users/jianannan/Desktop/ml-notes/LearningRateJustRight.svg)



#### 5. ä¼˜åŒ–å­¦ä¹ é€Ÿç‡

https://developers.google.com/machine-learning/crash-course/fitter/graphï¼Œè¿™ä¸ªé¡µé¢æœ‰ä¸€ä¸ªéå¸¸ç”ŸåŠ¨çš„Web Appï¼Œå¯ä»¥é€šè¿‡äº¤äº’å±•ç¤ºä¸Šè¿°è¿‡ç¨‹ã€‚



#### 6. éšæœºæ¢¯åº¦ä¸‹é™ç®—æ³•

åœ¨æ¢¯åº¦ä¸‹é™æ³•ä¸­ï¼Œ`æ‰¹é‡ï¼ˆbatchï¼‰`æŒ‡çš„æ˜¯ç”¨äºåœ¨å•æ¬¡è¿­ä»£ä¸­è®¡ç®—æ¢¯åº¦çš„æ ·æœ¬æ€»æ•°ã€‚

å½“ç›®å‰ä¸ºæ­¢ï¼Œæˆ‘ä»¬ä¸€ç›´å‡å®šæ‰¹é‡æ˜¯å…¨éƒ¨æ‰€æœ‰æ ·æœ¬ï¼ˆæ•´ä¸ªæ•°æ®é›†ï¼‰ï¼Œä½†æœ‰æ—¶å€™ï¼Œæ•°æ®é›†å¯èƒ½éå¸¸å·¨å¤§ï¼ŒåŒ…å«å‡ åäº¿ã€ä¸Šåƒäº¿æ¡æ ·æœ¬ï¼Œè¿™ä¸ªæ—¶å€™ï¼Œåœ¨é€‰æ‹©æ•´ä¸ªæ•°æ®é›†ä½œä¸ºæ‰¹é‡ï¼Œå°±ä¼šå¯¼è‡´å•æ¬¡è¿­ä»£è¦èŠ±è´¹å¾ˆé•¿æ—¶é—´ã€‚

å¹¶ä¸”ï¼Œæ‰¹é‡è¶Šå¤§ï¼ŒåŒ…å«å†—ä½™æ ·æœ¬ï¼ˆæˆ‘ç†è§£å°±æ˜¯ä¸åˆ©äºé«˜æ•ˆåœ°ç¡®å®šæœ€ä½³æƒé‡ï¼ˆä¾‹å¦‚ï¼šy' = b + w1x1 w1 å³ æƒé‡ï¼Œæ–œç‡ï¼‰çš„æ¦‚ç‡ä¹Ÿå°±è¶Šå¤§ã€‚æ‰€ä»¥ï¼Œè¶…å¤§æ‰¹é‡æ‰€å…·å¤‡çš„é¢„æµ‹ä»·å€¼å¾€å¾€å¹¶ä¸æ¯”å¤§å‹æ‰¹é‡é«˜ã€‚



`éšæœºæ¢¯åº¦ä¸‹é™ç®—æ³•ï¼ˆSGDï¼‰`æ¯æ¬¡åªè¿­ä»£ä¸€ä¸ªæ ·æœ¬ï¼Œä¸”æ ·æœ¬å‡ä¸ºéšæœºæŒ‘é€‰ï¼Œä»è€Œé€šè¿‡æ›´å°‘çš„è®¡ç®—é‡å¾—å‡ºæ­£ç¡®çš„å¹³å‡æ¢¯åº¦ã€‚

**å°æ‰¹é‡(mini-batch)éšæœºæ¢¯åº¦ä¸‹é™æ³•**ï¼ˆ**å°æ‰¹é‡ SGD**ï¼‰æ˜¯ä»‹äºå…¨æ‰¹é‡è¿­ä»£ä¸ SGD ä¹‹é—´çš„æŠ˜è¡·æ–¹æ¡ˆã€‚å°æ‰¹é‡é€šå¸¸åŒ…å« 10-1000 ä¸ªéšæœºé€‰æ‹©çš„æ ·æœ¬ã€‚å°æ‰¹é‡ SGD å¯ä»¥å‡å°‘ SGD ä¸­çš„æ‚ä¹±æ ·æœ¬æ•°é‡ï¼Œä½†ä»ç„¶æ¯”å…¨æ‰¹é‡æ›´é«˜æ•ˆã€‚



#### 7. playground

å­¦ä¹ é€Ÿç‡å’Œæ”¶æ•›ï¼šhttps://developers.google.com/machine-learning/crash-course/reducing-loss/playground-exercise#%E5%AD%A6%E4%B9%A0%E9%80%9F%E7%8E%87%E5%92%8C%E6%94%B6%E6%95%9B



#### 8. ç»ƒä¹ é¢˜

åŸºäºå¤§å‹æ•°æ®é›†æ‰§è¡Œæ¢¯åº¦ä¸‹é™æ³•æ—¶ï¼Œä»¥ä¸‹å“ªä¸ªæ‰¹é‡å¤§å°å¯èƒ½æ¯”è¾ƒé«˜æ•ˆï¼Ÿ

- å…¨æ‰¹é‡ã€‚

- å°æ‰¹é‡æˆ–ç”šè‡³åŒ…å«ä¸€ä¸ªæ ·æœ¬çš„æ‰¹é‡ (SGD)ã€‚

ä»¤äººæƒŠè®¶çš„æ˜¯ï¼Œåœ¨å°æ‰¹é‡æˆ–ç”šè‡³åŒ…å«ä¸€ä¸ªæ ·æœ¬çš„æ‰¹é‡ä¸Šæ‰§è¡Œæ¢¯åº¦ä¸‹é™æ³•é€šå¸¸æ¯”å…¨æ‰¹é‡æ›´é«˜æ•ˆã€‚æ¯•ç«Ÿï¼Œè®¡ç®—ä¸€ä¸ªæ ·æœ¬çš„æ¢¯åº¦è¦æ¯”è®¡ç®—æ•°ç™¾ä¸‡ä¸ªæ ·æœ¬çš„æ¢¯åº¦æˆæœ¬ä½çš„å¤šã€‚ä¸ºç¡®ä¿è·å¾—è‰¯å¥½çš„ä»£è¡¨æ€§æ ·æœ¬ï¼Œè¯¥ç®—æ³•åœ¨æ¯æ¬¡è¿­ä»£æ—¶éƒ½ä¼šæŠ½å–å¦ä¸€ä¸ªéšæœºå°æ‰¹é‡æ•°æ®ï¼ˆæˆ–åŒ…å«ä¸€ä¸ªæ ·æœ¬çš„æ‰¹é‡æ•°æ®ï¼‰ã€‚





> å­¦åˆ°è¿™é‡Œï¼Œæˆ‘æœ‰ä¸€ä¸ªæ„Ÿå—ï¼Œæ–‡æ¡£ä¸­çš„å¾ˆå¤šåè¯è®©æˆ‘æ„Ÿè§‰å¾ˆé™Œç”Ÿï¼Œä¾‹å¦‚æƒé‡ã€æ”¶æ•›ã€æ ‡ç­¾ã€ç‰¹å¾ç­‰ç­‰ï¼Œå¾ˆå½±å“æˆ‘çš„å­¦ä¹ æ•ˆç‡ï¼Œå¯èƒ½å› ä¸ºä»¥ä¸‹ä¸¤æ–¹é¢åŸå› ï¼š

> - ä¸ªäººçš„æ•°å­¦åŸºç¡€ä¸å¥½ï¼Œå¯¹è¿™äº›æ•°å­¦æ¦‚å¿µä¸ç†Ÿæ‚‰ã€‚
> - è¿™äº›åè¯çš„ä¸­æ–‡ç¿»è¯‘ä¹Ÿè¿‡äºç”Ÿç¡¬ï¼Œä¸å¤Ÿä¿¡é›…è¾¾ã€‚





### äº”ã€ä½¿ç”¨ TensorFlow çš„èµ·å§‹æ­¥éª¤ (First Steps with TensorFlow)



#### 1. å·¥å…·åŒ…

TensorFlow å·¥å…·åŒ…æœ‰å¤šä¸ªå±‚æ¬¡çš„ API å¯ä¾›ä½¿ç”¨ï¼Œæˆ‘ä»¬ä¸»è¦å­¦ä¹  `tf.estimator é¢å‘å¯¹è±¡çš„é«˜çº§API`ã€‚

æ‚¨åœ¨ç»ƒä¹ ä¸­æ‰€åšçš„ä¸€åˆ‡éƒ½å¯ä»¥åœ¨è¾ƒä½çº§åˆ«ï¼ˆåŸå§‹ï¼‰çš„ TensorFlow ä¸­å®Œæˆï¼Œä½†ä½¿ç”¨ tf.estimator ä¼šå¤§å¤§å‡å°‘ä»£ç è¡Œæ•°ã€‚



#### 2. ç¼–ç¨‹ç»ƒä¹ 

> Excitedï¼ç»ˆäºä¸Šæ‰‹äº†ï¼

1. é¦–å…ˆï¼Œéœ€è¦ç†Ÿæ‚‰ä¸€ä¸‹ å¹¿æ³›åº”ç”¨äº TensorFlow ç¼–ç è¿›è¡Œæ•°æ®åˆ†æå’Œå»ºæ¨¡çš„é‡è¦åº“â€”â€”Pandasã€‚è¿™ä¸ªåº“å¯ä»¥æ–¹ä¾¿åœ°å¯¹æ•°æ®é›†è¿›è¡Œæ ¼å¼åŒ–å¤„ç†ï¼Œä»¥ç¬¦åˆ TensorFlow è®­ç»ƒçš„éœ€è¦ã€‚
2. [ä½¿ç”¨ TensorFlow çš„èµ·å§‹æ­¥éª¤](https://colab.research.google.com/notebooks/mlcc/first_steps_with_tensor_flow.ipynb?utm_source=mlcc&utm_campaign=colab-external&utm_medium=referral&utm_content=firststeps-colab&hl=zh-cn)ï¼šæ­¤ç»ƒä¹ ä»‹ç»äº†çº¿æ€§å›å½’ã€‚

**VIP: **

è¿™ä¸€èŠ‚ç»ƒä¹ å±•ç¤ºäº†ä¸€æ¬¡å®Œæ•´çš„åˆ©ç”¨çº¿æ€§å›å½’è®­ç»ƒæ¨¡å‹ï¼Œå¹¶é€šè¿‡å‡æ–¹æ ¹è¯¯å·®ï¼ˆRMSEï¼‰æ¥è¯„ä¼°æ¨¡å‹çš„å‡†ç¡®ç‡çš„è¿‡ç¨‹ã€‚

å¤§è‡´æµç¨‹æ˜¯è¿™æ ·çš„ï¼š

1. å®šä¹‰`ç‰¹å¾`å¹¶é…ç½® `ç‰¹å¾åˆ—` ã€ `ç›®æ ‡ï¼ˆæ ‡ç­¾ï¼‰`

å¤ä¹ ï¼š

`æ ‡ç­¾ï¼ˆlabelï¼‰`ï¼ˆæœ‰æ—¶ç§°ä¸º`ç›®æ ‡`ï¼‰ï¼šæŒ‡æˆ‘ä»¬è¦é¢„æµ‹çš„çœŸå®äº‹ç‰©ï¼š**y**ï¼Œä¾‹å¦‚åƒåœ¾é‚®ä»¶è¿‡æ»¤ä¸­çš„â€œåƒåœ¾é‚®ä»¶æˆ–éåƒåœ¾é‚®ä»¶â€ï¼Œæ­¤å¤„æ˜¯ä¸€ä¸ªè¡—åŒºå†…æˆ¿å±‹çš„å‡ä»·ã€‚

`ç‰¹å¾ï¼ˆfeatureï¼‰`ï¼šæŒ‡ç”¨äºæè¿°æ•°æ®çš„è¾“å…¥å˜é‡ï¼š**xä¸‹æ ‡i**ï¼Œä¾‹å¦‚é‚®ä»¶çš„å†…å®¹ã€æ ‡é¢˜ã€æ”¶å‘ä»¶äººã€‚â€ï¼Œæ­¤å¤„ç”¨çš„æ˜¯è¡—åŒºçš„æˆ¿å±‹æ€»æ•°é‡ã€‚

å³ï¼Œç”¨ä¸€ä¸ªè¡—åŒºçš„æˆ¿å±‹æ€»æ•°é‡æ¥é¢„æµ‹è¿™ä¸ªè¡—åŒºçš„æˆ¿é—´ä»·æ ¼ï¼Œè®­ç»ƒå‡ºæ¥çš„æ¨¡å‹æè¿°çš„æ˜¯ï¼Œè¡—åŒºçš„æˆ¿å±‹æ€»æ•°é‡å’Œæˆ¿å±‹å‡ä»·ä¹‹é—´çš„å…³ç³»ã€‚

```python
# Define the input feature: total_rooms.
my_feature = california_housing_dataframe[["total_rooms"]]

# Configure a numeric feature column for total_rooms.
feature_columns = [tf.feature_column.numeric_column("total_rooms")]


# Define the label/target.
targets = california_housing_dataframe["median_house_value"]
```





2. é…ç½® çº¿æ€§å›å½’ æ¨¡å‹ï¼Œå¹¶ä½¿ç”¨ `GradientDescentOptimizer`ï¼ˆå®ƒä¼šå®ç°å°æ‰¹é‡éšæœºæ¢¯åº¦ä¸‹é™æ³• (SGD)ï¼‰è®­ç»ƒè¯¥æ¨¡å‹ã€‚`learning_rate` å‚æ•°å¯æ§åˆ¶æ¢¯åº¦æ­¥é•¿çš„å¤§å°ã€‚

```python
# Use gradient descent as the optimizer for training the model.
my_optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.0000001)

# æ³¨æ„ï¼šä¸ºäº†å®‰å…¨èµ·è§ï¼Œæˆ‘ä»¬è¿˜ä¼šé€šè¿‡ clip_gradients_by_norm å°†æ¢¯åº¦è£å‰ªåº”ç”¨åˆ°æˆ‘ä»¬çš„ä¼˜åŒ–å™¨ã€‚æ¢¯åº¦è£å‰ªå¯ç¡®ä¿æ¢¯åº¦å¤§å°åœ¨è®­ç»ƒæœŸé—´ä¸ä¼šå˜å¾—è¿‡å¤§ï¼Œæ¢¯åº¦è¿‡å¤§ä¼šå¯¼è‡´æ¢¯åº¦ä¸‹é™æ³•å¤±è´¥ã€‚
my_optimizer = tf.contrib.estimator.clip_gradients_by_norm(my_optimizer, 5.0)


# Configure the linear regression model with our feature columns and optimizer.
# Set a learning rate of 0.0000001 for Gradient Descent.
linear_regressor = tf.estimator.LinearRegressor(
    feature_columns=feature_columns,
    optimizer=my_optimizer
)
```





3. å®šä¹‰è¾“å…¥å‡½æ•°ï¼Œæ ¼å¼åŒ–è¾“å…¥æ•°æ®ä¸º`ä¸€ä¸ªæ‰¹é‡ï¼ˆbatchï¼‰`çš„ `LinearRegressor` å¯ä»¥å¤„ç†çš„`ç‰¹å¾ - æ ‡ç­¾é”®å€¼å¯¹(return features, labels)`

````python
def my_input_fn(features, targets, batch_size=1, shuffle=True, num_epochs=None):
    """Trains a linear regression model of one feature.
  
    Args:
      features: pandas DataFrame of features
      targets: pandas DataFrame of targets
      batch_size: Size of batches to be passed to the model
      shuffle: True or False. Whether to shuffle the data.
      num_epochs: Number of epochs for which data should be repeated. None = repeat indefinitely
    Returns:
      Tuple of (features, labels) for next data batch
    """
  
    # Convert pandas data into a dict of np arrays.
    features = {key:np.array(value) for key,value in dict(features).items()}                                           
 
    # Construct a dataset, and configure batching/repeating.
    ds = Dataset.from_tensor_slices((features,targets)) # warning: 2GB limit
    ds = ds.batch(batch_size).repeat(num_epochs)
    
    # Shuffle the data, if specified.
    if shuffle:
      ds = ds.shuffle(buffer_size=10000)
    
    # Return the next batch of data.
    features, labels = ds.make_one_shot_iterator().get_next()
    return features, labels
````



4. åˆæ­¥è®­ç»ƒå¹¶è¯„ä¼°æ¨¡å‹

è®­ç»ƒ 100 æ­¥ï¼š

```python
_ = linear_regressor.train(
    input_fn = lambda:my_input_fn(my_feature, targets),
    steps=100
)
```

åŸºäºè®­ç»ƒ100æ¬¡åçš„è¯¥è®­ç»ƒæ¨¡å‹ï¼ˆlinear_regressorï¼‰åšä¸€æ¬¡é¢„æµ‹ï¼Œçœ‹çœ‹æˆ‘ä»¬çš„æ¨¡å‹åœ¨è®­ç»ƒæœŸé—´ä¸è¿™äº›æ•°æ®çš„æ‹Ÿåˆæƒ…å†µã€‚

```python
# Create an input function for predictions.
# Note: Since we're making just one prediction for each example, we don't 
# need to repeat or shuffle the data here.
prediction_input_fn =lambda: my_input_fn(my_feature, targets, num_epochs=1, shuffle=False)

# Call predict() on the linear_regressor to make predictions.
predictions = linear_regressor.predict(input_fn=prediction_input_fn)

# Format predictions as a NumPy array, so we can calculate error metrics.
predictions = np.array([item['predictions'][0] for item in predictions])

# Print Mean Squared Error and Root Mean Squared Error.
mean_squared_error = metrics.mean_squared_error(predictions, targets)
root_mean_squared_error = math.sqrt(mean_squared_error)
print("Mean Squared Error (on training data): %0.3f" % mean_squared_error)
print("Root Mean Squared Error (on training data): %0.3f" % root_mean_squared_error)
```

Output:

```
Mean Squared Error (on training data): 56425.111
Root Mean Squared Error (on training data): 237.540
```

å¯ä»¥é€šè¿‡æ¯”è¾ƒ RMSE ä¸ç›®æ ‡æœ€å¤§å€¼å’Œæœ€å°å€¼çš„å·®å€¼æ¥åˆ¤æ–­è¿™ä¸ªæ¨¡å‹çš„è´¨é‡

```python
min_house_value = california_housing_dataframe["median_house_value"].min()
max_house_value = california_housing_dataframe["median_house_value"].max()
min_max_difference = max_house_value - min_house_value

print("Min. Median House Value: %0.3f" % min_house_value)
print("Max. Median House Value: %0.3f" % max_house_value)
print("Difference between Min. and Max.: %0.3f" % min_max_difference)
print("Root Mean Squared Error: %0.3f" % root_mean_squared_error)
```

output:

```
Min. Median House Value: 14.999
Max. Median House Value: 500.001
Difference between Min. and Max.: 485.002
Root Mean Squared Error: 237.295
```

è¯¯å·®è·¨è¶Šç›®æ ‡å€¼çš„è¿‘ä¸€åŠèŒƒå›´ï¼Œæ€»çš„ç›®æ ‡ - æˆ¿ä»·èŒƒå›´æ˜¯14è‡³500ï¼Œä½†æ€»è¯¯å·®ä¹‹å’Œçš„Nåˆ†ä¹‹ä¸€ï¼Œå‡æ–¹æ ¹è¯¯å·®è¾¾åˆ°äº†237ï¼Œæ ‡ç¤ºé¢„æµ‹ç»“æœçš„è¯¯å·®å¯èƒ½å’ŒçœŸå®æƒ…å†µæœ‰237çš„å·®å€¼ã€‚

éœ€è¦è¿›ä¸€æ­¥ç¼©å°è¯¯å·®ã€‚



> æ•ˆæœè¶Šå¥½ï¼Œå›å½’çº¿ä¸æ•°æ®çš„æ‹Ÿåˆåº¦ï¼ˆ`æ‹Ÿåˆåº¦`å³æ¨¡å‹ä¸[**è®­ç»ƒæ•°æ®**](https://developers.google.com/machine-learning/glossary/#training_set)åŒ¹é…çš„ç¨‹åº¦ï¼‰å°±è¶Šé«˜ï¼Œæœ€ç»ˆ RMSE ï¼ˆå‡æ–¹æ ¹è¯¯å·®ï¼‰ ä¹Ÿä¼šè¶Šä½ã€‚
>
> â€”â€” [åˆæˆç‰¹å¾å’Œç¦»ç¾¤å€¼](https://colab.research.google.com/notebooks/mlcc/synthetic_features_and_outliers.ipynb?utm_source=mlcc&utm_campaign=colab-external&utm_medium=referral&utm_content=syntheticfeatures-colab&hl=zh-cn)

> ##### è¿‡æ‹Ÿåˆ (overfitting)
>
> åˆ›å»ºçš„æ¨¡å‹ä¸[**è®­ç»ƒæ•°æ®**](https://developers.google.com/machine-learning/glossary/#training_set)è¿‡äºåŒ¹é…ï¼Œä»¥è‡´äºæ¨¡å‹æ— æ³•æ ¹æ®æ–°æ•°æ®åšå‡ºæ­£ç¡®çš„é¢„æµ‹ã€‚



å¤ä¹ ï¼š

`RMSE - å‡æ–¹æ ¹è¯¯å·®`å¯ä»¥ç”¨æ¥åˆ¤æ–­æ¨¡å‹çš„è´¨é‡å’Œè¯¯å·®å¤§å°ï¼ŒRMSE çš„ä¸€ä¸ªå¾ˆå¥½çš„ç‰¹æ€§æ˜¯ï¼Œå®ƒå¯ä»¥åœ¨ä¸åŸç›®æ ‡ç›¸åŒçš„è§„æ¨¡ä¸‹è§£è¯»ã€‚

æˆ‘ä»¬ç”¨`å¹³æ–¹æŸå¤±ï¼ˆL2æŸå¤±ï¼‰`æ¥æ›´ç§‘å­¦åœ°æ±‡æ€»ä¸€ä¸ªæ¨¡å‹çš„æŸå¤±ã€‚

- å•ä¸ªæ ·æœ¬çš„`å¹³æ–¹æŸå¤±`å…¬å¼å¦‚ä¸‹ï¼š

```
  = the square of the difference between the label and the prediction
  = (observation - prediction(x))2
  = (y - y')2
```

- æ¯ä¸ªæ ·æœ¬çš„å¹³å‡å¹³æ–¹æŸå¤±ç§°ä¹‹ä¸ºï¼š**å‡æ–¹è¯¯å·®** (**MSE - Mean Squared Error**)ï¼Œå…¬å¼å¦‚ä¸‹ï¼š

![mse-formula](/Users/jianannan/Desktop/ml-notes/mse-formula.png)

- `RMSEï¼ˆå‡æ–¹æ ¹è¯¯å·®ï¼‰ = å‡æ–¹è¯¯å·® å¼€æ ¹å·`



è¿˜å¯ä»¥åˆ©ç”¨ `æ•°å½¢ç»“åˆ` åˆ¤æ–­æ¨¡å‹çš„è´¨é‡ï¼š

```
...
```



![model-plot](/Users/jianannan/Desktop/ml-notes/model-plot.png)

å›¾ä¸­è“ç‚¹ä¸ºæ ·æœ¬ï¼Œçº¢çº¿ä¸ºæ¨¡å‹ï¼Œå¯ä»¥ç›´è§‚åœ°çœ‹å‡ºï¼Œåå·®è¾ƒå¤§ã€‚





5. è°ƒæ•´è¶…å‚æ•°ï¼Œé‡æ–°è®­ç»ƒæ¨¡å‹ï¼Œé™ä½æŸå¤±ï¼Œä¿ƒè¿›æ¨¡å‹æ”¶æ•›

å°†æ•´ä¸ªè®­ç»ƒè¿‡ç¨‹å°è£…æˆä¸€ä¸ªå‡½æ•°ï¼Œæ–¹ä¾¿è°ƒè¯•ã€è®­ç»ƒã€‚

```python
def train_model(learning_rate, steps, batch_size, input_feature="total_rooms"):

....
```



```
train_model(
    learning_rate=0.0001,
    steps=200,
    batch_size=1
)
```

Output:

```
Training model...
RMSE (on training data):
  period 00 : 214.42
  period 01 : 194.62
  period 02 : 180.53
  period 03 : 170.91
  period 04 : 167.02
  period 05 : 166.53
  period 06 : 167.02
  period 07 : 168.84
  period 08 : 170.92
  period 09 : 173.57
Model training finished.
```



![change-super-params-traning](/Users/jianannan/Desktop/ml-notes/change-super-params-traning.png)

é€šè¿‡å¤šæ¬¡è°ƒæ•´è¶…å‚æ•°ï¼ˆlearning_rateã€stepç­‰ï¼‰å¯ä»¥å‘ç°ï¼Œä¸åŒçš„è¶…å‚æ•°å¯¹æ¨¡å‹çš„æŸå¤±ã€è®­ç»ƒç”¨æ—¶ç­‰å‡æœ‰æ˜¾è‘—çš„ä¸åŒå½±å“ã€‚



ä¹Ÿå¯ä»¥é€šè¿‡è°ƒæ•´ ç‰¹å¾ï¼ŒéªŒè¯å…¶å¯¹æ¨¡å‹çš„å½±å“ï¼š

```python
train_model(
    learning_rate=0.0002,
    steps=200,
    batch_size=1,
    input_feature="population"
)
```



2018/10/28



3. [åˆæˆç‰¹å¾å’Œç¦»ç¾¤å€¼](https://colab.research.google.com/notebooks/mlcc/synthetic_features_and_outliers.ipynb?utm_source=mlcc&utm_campaign=colab-external&utm_medium=referral&utm_content=syntheticfeatures-colab&hl=zh-cn)

è¿™ä¸€èŠ‚ç»ƒä¹ åœ¨ä¸Šä¸€èŠ‚ç»ƒä¹ çš„åŸºç¡€ä¸Šï¼Œä»‹ç»äº†ï¼š

- é€šè¿‡`å°†ä¸¤ä¸ªç‰¹å¾åˆæˆä¸ºä¸€ä¸ª åˆæˆç‰¹å¾`æ¥å½“ä½œçº¿æ€§å›å½’çš„è¾“å…¥è®­ç»ƒæ¨¡å‹ã€‚

æˆ‘è‡ªå·±çš„å°è¯•æ—¶ï¼Œå†™å‡ºäº†å¦‚ä¸‹ä»£ç ï¼š

```python
california_housing_dataframe["rooms_per_person"] = 1000 * (california_housing_dataframe["population"] / ( california_housing_dataframe["total_rooms"]))

calibration_data = train_model(
    learning_rate=0.0003,
    steps=200,
    batch_size=5,
    input_feature="rooms_per_person"
)


Training model...
RMSE (on training data):
  period 00 : 223.98
  period 01 : 212.23
  period 02 : 202.60
  period 03 : 196.01
  period 04 : 191.25
  period 05 : 189.43
  period 06 : 190.03
  period 07 : 191.76
  period 08 : 192.15
  period 09 : 193.99
Model training finished.
```



`1000 *`æ˜¯å› ä¸ºï¼Œæˆ‘å‘ç°ä¸åŠ è¿™ä¸ª RMSE  å‡æ–¹æ ¹è¯¯å·® ä¸‹é™çš„å¾ˆæ…¢ï¼ŒåŠ ä¸Šä¹‹åï¼Œå¾ˆå¿«å°±èƒ½ä¸‹é™åˆ° 200 ä»¥ä¸‹ã€‚

çœ‹äº†å‚è€ƒç­”æ¡ˆåï¼ŒçŸ¥é“è¿™ä¸ªæ€è·¯ä¸å¤ªå¯¹ï¼Œåº”è¯¥é€šè¿‡`è°ƒæ•´è¶…å‚æ•°æ¥é™ä½æŸå¤±`ã€‚

```python
california_housing_dataframe["rooms_per_person"] = (
    california_housing_dataframe["total_rooms"] / california_housing_dataframe["population"])

# åº”è¯¥é€šè¿‡åŠ å¤§ å­¦ä¹ é€Ÿç‡ å’Œ æ­¥ï¼Œæ¥åŠ å¿«æŸå¤±çš„é™ä½
calibration_data = train_model(
    learning_rate=0.05,
    steps=500,
    batch_size=5,
    input_feature="rooms_per_person")
```



```
Training model...
RMSE (on training data):
  period 00 : 212.76
  period 01 : 189.71
  period 02 : 169.05
  period 03 : 151.68
  period 04 : 141.42
  period 05 : 134.12
  period 06 : 131.18
  period 07 : 130.64
  period 08 : 130.88
  period 09 : 131.29
Model training finished.
```





- é€šè¿‡è¯†åˆ«å’Œæˆªå–ï¼ˆç§»é™¤ï¼‰è¾“å…¥æ•°æ®ä¸­çš„ç¦»ç¾¤å€¼ï¼ˆå¤§äºä¸€å®šç•Œé™çš„å€¼ï¼‰æ¥æé«˜æ¨¡å‹çš„æœ‰æ•ˆæ€§ã€‚

> æˆ‘ä»¬å¯ä»¥é€šè¿‡åˆ›å»ºé¢„æµ‹å€¼ä¸ç›®æ ‡å€¼çš„æ•£ç‚¹å›¾æ¥å¯è§†åŒ–æ¨¡å‹æ•ˆæœã€‚
>
> ç†æƒ³æƒ…å†µä¸‹ï¼Œè¿™äº›å€¼å°†ä½äºä¸€æ¡å®Œå…¨ç›¸å…³çš„å¯¹è§’çº¿ä¸Šã€‚

ä½†å®é™…ä¸Šï¼Œç»“æœæ˜¯è¿™æ ·çš„ï¼š

```python
# calibration_data = train_model(
    learning_rate=0.05,
    steps=500,
    batch_size=5,
    input_feature="rooms_per_person")

plt.figure(figsize=(15, 6))
plt.subplot(1, 2, 1)
plt.scatter(calibration_data["predictions"], calibration_data["targets"])
```



![outliners-1](/Users/jianannan/Desktop/ml-notes/outliners-1.png)

å¤§å¤šæ•°æ ¹æ®è®­ç»ƒè¿‡çš„æ¨¡å‹å¾—åˆ°çš„é¢„æµ‹å€¼éƒ½ä¸ä¸€æ¡å‡ ä¹å‚ç›´çš„çº¿å¯¹é½ï¼Œä¹Ÿæœ‰ç›¸å¯¹è¾ƒå°‘çš„ç‚¹è¿œè¿œåç¦»è¿™æ¡å‚ç›´çš„çº¿ï¼Œè¿™ä¸¤ç‚¹åœ¨ç›´æ–¹å›¾ğŸ“Šä¸Šå°¤å…¶æ˜æ˜¾ï¼š

![outliers-zhifangtu](/Users/jianannan/Desktop/ml-notes/outliers-zhifangtu.png)

å¦‚æœèƒ½`æ’é™¤ï¼ˆæˆªå–ï¼‰`æ‰å å°‘æ•°çš„ç¦»ç¾¤å€¼ï¼Œå¯¹æ¨¡å‹çš„`æ‹Ÿåˆæƒ…å†µï¼ˆæ¨¡å‹ä¸è®­ç»ƒæ•°æ®åŒ¹é…çš„æƒ…å†µï¼‰`ä¼šæœ‰å¾ˆå¤§çš„æ”¹å–„ã€‚

å¯ä»¥è¿™æ ·åšï¼š

```python
california_housing_dataframe["rooms_per_person"] = (
    california_housing_dataframe["rooms_per_person"]).apply(lambda x: min(x, 5))

_ = california_housing_dataframe["rooms_per_person"].hist()
```

![outliers-zhifangtu-2](/Users/jianannan/Desktop/ml-notes/outliers-zhifangtu-2.png)

å†æ¬¡è®­ç»ƒï¼Œä¼šå‘ç°æ¨¡å‹çš„æ‹Ÿåˆåº¦å¥½å¤šäº†ï¼š

![training_after_outliers](/Users/jianannan/Desktop/ml-notes/training_after_outliers.png)

å†æ¬¡åˆ›å»ºé¢„æµ‹å€¼ä¸ç›®æ ‡å€¼çš„æ•£ç‚¹å›¾æ¥å¯è§†åŒ–åœ°è§‚å¯Ÿæ¨¡å‹æ•ˆæœä¹Ÿèƒ½çœ‹å‡ºè¿™ä¸€ç‚¹ï¼š



![fitting-after-outliers](/Users/jianannan/Desktop/ml-notes/fitting-after-outliers.png)







2018/10/31